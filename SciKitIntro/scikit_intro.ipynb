{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1.\n",
    "Writing custom scikit-learn transformers is a convenient way to organize the data\n",
    "cleaning process. Consider the data in titanic.csv, which contains information about passengers on the maiden voyage of the RMS Titanic in 1912. Write a custom transformer class to\n",
    "clean this data, implementing the transform() method as follows:\n",
    "1. Extract a copy of data frame with just the \"Pclass\", \"Sex\", and \"Age\" columns.\n",
    "2. Replace NaN values in the \"Age\" column (of the copied data frame) with the mean age.\n",
    "The mean age of the training data should be calculated in fit() and used in transform()\n",
    "(compare this step to using sklearn.preprocessing.Imputer).\n",
    "3. Convert the \"Pclass\" column datatype to pandas categoricals (pd.CategoricalIndex).\n",
    "4. Use pd.get_dummies() to convert the categorical columns to multiple binary columns\n",
    "(compare this step to using sklearn.preprocessing.OneHotEncoder).\n",
    "5. Cast the result as a NumPy array and return it.\n",
    "Ensure that your transformer matches scikit-learn conventions (it inherits from the correct base\n",
    "classes, fit() returns self, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, return_array=True):\n",
    "        self.return_array = return_array\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.data = X[[\"Pclass\", \"Sex\", \"Age\"]]\n",
    "        self.age_mean = X.Age.mean()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X[[\"Pclass\", \"Sex\", \"Age\"]]\n",
    "        X.Age = X.Age.fillna(self.age_mean)\n",
    "        X.Pclass = pd.CategoricalIndex(X.Pclass)\n",
    "        X = pd.get_dummies(X, columns=[\"Sex\", \"Pclass\"], drop_first=True)\n",
    "        if self.return_array:\n",
    "            return np.array(X)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.    ,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.9167,  1.    ,  0.    ,  0.    ],\n",
       "       [ 2.    ,  0.    ,  0.    ,  0.    ],\n",
       "       [30.    ,  1.    ,  0.    ,  0.    ],\n",
       "       [25.    ,  0.    ,  0.    ,  0.    ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = TitanicTransformer()\n",
    "titanic = pd.read_csv(\"titanic.csv\")\n",
    "X_train = transform.fit_transform(titanic)\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. \n",
    "Read the data from titanic.csv with pd.read_csv(). The \"Survived\" column\n",
    "indicates which passengers survived, so the entries of the column are the labels that we would\n",
    "like to predict. Drop any rows in the raw data that have NaN values in the \"Survived\" column,\n",
    "then separate the column from the rest of the data. Split the data and labels into training and\n",
    "testing sets. Use the training data to fit a transformer from Problem 1, then use that transformer\n",
    "to clean the training set, then the testing set. Finally, train a LogisticRegressionClassifier\n",
    "and a RandomForestClassifier on the cleaned training data, and score them using the cleaned\n",
    "test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sibsp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Boat</th>\n",
       "      <th>Body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived                                             Name     Sex  \\\n",
       "0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
       "2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
       "3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       Age  Sibsp  Parch  Ticket      Fare    Cabin Embarked Boat   Body  \\\n",
       "0  29.0000    0.0    0.0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167    1.0    2.0  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"titanic.csv\").dropna(subset=[\"Survived\"])\n",
    "titanic[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(981, 13) (981,)\n",
      "(328, 13) (328,)\n"
     ]
    }
   ],
   "source": [
    "X = titanic.drop(columns=[\"Survived\"])\n",
    "y = titanic.Survived.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((981, 4), (328, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = TitanicTransformer()\n",
    "Z_train = tt.fit_transform(X_train)\n",
    "Z_test = tt.transform(X_test)\n",
    "Z_train.shape, Z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression prediction score\n",
      "0.7774390243902439\n"
     ]
    }
   ],
   "source": [
    "log_reg = sklearn.linear_model.LogisticRegression()\n",
    "log_reg.fit(Z_train, y_train)\n",
    "print(\"Logistic Regression prediction score\")\n",
    "print(log_reg.score(Z_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest prediction score\n",
      "0.774390243902439\n"
     ]
    }
   ],
   "source": [
    "rand_frst = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "rand_frst.fit(Z_train, y_train)\n",
    "print(\"Random Forest prediction score\")\n",
    "print(rand_frst.score(Z_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3. \n",
    "Use classification_report() to score your classifiers from Problem 2. Next,\n",
    "do a grid search for each classifier (using only the cleaned training data), varying at least two hyperparameters for each kind of model. Use classification_report() to score the resulting\n",
    "best estimators with the cleaned test data. Try changing the hyperparameter spaces or scoring\n",
    "metrics so that each grid search yields a better estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.90      0.83       201\n",
      "          1       0.79      0.58      0.67       127\n",
      "\n",
      "avg / total       0.78      0.78      0.77       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predicted = log_reg.predict(Z_test)\n",
    "print(classification_report(y_test, lr_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.98      0.84       201\n",
      "          1       0.92      0.46      0.61       127\n",
      "\n",
      "avg / total       0.81      0.77      0.75       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predicted = rand_frst.predict(Z_test)\n",
    "print(classification_report(y_test, rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1'} 0.7859327217125383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.90      0.83       201\n",
      "          1       0.79      0.58      0.67       127\n",
      "\n",
      "avg / total       0.78      0.78      0.77       328\n",
      "\n",
      "{'C': 0.3} 0.780835881753313\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.89      0.83       201\n",
      "          1       0.78      0.60      0.68       127\n",
      "\n",
      "avg / total       0.78      0.78      0.77       328\n",
      "\n",
      "{'C': 0.64} 0.780835881753313\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.90      0.83       201\n",
      "          1       0.79      0.58      0.67       127\n",
      "\n",
      "avg / total       0.78      0.78      0.77       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "lr_param_grid = {\"penalty\": [\"l1\", \"l2\"],\n",
    "                 \"C\": [0.01, 0.1, 0.5, 1, 2, 10, 100]}\n",
    "lr_gs = GridSearchCV(log_reg, lr_param_grid, cv=4, scoring=\"accuracy\")\n",
    "lr_gs.fit(Z_train, y_train)\n",
    "print(lr_gs.best_params_, lr_gs.best_score_)\n",
    "lr_gs_predicted = lr_gs.predict(Z_test)\n",
    "print(classification_report(y_test, lr_gs_predicted))\n",
    "lr_param_grid = {\"C\": [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}\n",
    "lr_gs = GridSearchCV(log_reg, lr_param_grid, cv=4, scoring=\"accuracy\")\n",
    "lr_gs.fit(Z_train, y_train)\n",
    "lr_gs_predicted = lr_gs.predict(Z_test)\n",
    "print(lr_gs.best_params_, lr_gs.best_score_)\n",
    "print(classification_report(y_test, lr_gs_predicted))\n",
    "lr_param_grid = {\"C\": [0.64 + i/100 for i in range(10)]}\n",
    "lr_gs = GridSearchCV(log_reg, lr_param_grid, cv=4, scoring=\"accuracy\")\n",
    "lr_gs.fit(Z_train, y_train)\n",
    "lr_gs_predicted = lr_gs.predict(Z_test)\n",
    "print(lr_gs.best_params_, lr_gs.best_score_)\n",
    "print(classification_report(y_test, lr_gs_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 6, 'n_estimators': 200} 0.8012232415902141\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.93      0.85       201\n",
      "          1       0.84      0.57      0.68       127\n",
      "\n",
      "avg / total       0.80      0.79      0.78       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_frst = RandomForestClassifier()\n",
    "rf_param_grid = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "                 \"n_estimators\": [10, 50, 100, 150, 200, 250, 300],\n",
    "                 \"max_depth\": [2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "rf_gs = GridSearchCV(rand_frst, rf_param_grid, cv=4, scoring=\"accuracy\")\n",
    "rf_gs.fit(Z_train, y_train)\n",
    "print(rf_gs.best_params_, rf_gs.best_score_)\n",
    "rf_gs_predicted = rf_gs.predict(Z_test)\n",
    "print(classification_report(y_test, rf_gs_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4. \n",
    "Make a pipeline with at least two transformers to further process the Titanic\n",
    "dataset. Do a gridsearch on the pipeline and report the hyperparameters of the best estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeToCategorical(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None, boundary_points=[12, 18, 35, 60]):\n",
    "        self.bp = boundary_points\n",
    "        self.data = X.Age\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X.loc[X.Age < self.bp[0], \"Age_group\"] = \"Child\"\n",
    "        X.loc[(X.Age >= self.bp[0]) & (X.Age < self.bp[1]), \"Age_group\"] = \"Teen\"\n",
    "        X.loc[(X.Age >= self.bp[1]) & (X.Age < self.bp[2]), \"Age_group\"] = \"Young Adult\"\n",
    "        X.loc[(X.Age >= self.bp[2]) & (X.Age < self.bp[3]), \"Age_group\"] = \"Middle-aged\"\n",
    "        X.loc[X.Age >= self.bp[3], \"Age_group\"] = \"Senior\"\n",
    "        X = pd.get_dummies(X, columns=[\"Age_group\"], drop_first=True)\n",
    "        X.drop(columns=[\"Age\"])\n",
    "        return np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Seong-EunCho/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Seong-EunCho/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Seong-EunCho/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Seong-EunCho/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Seong-EunCho/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'log_reg__C': 10.0, 'log_reg__penalty': 'l1'} 0.7150306297107987\n",
      "[[181  20]\n",
      " [ 52  75]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([(\"titanic\", TitanicTransformer(return_array=False)),\n",
    "                 (\"age_group\", AgeToCategorical()),\n",
    "                 (\"log_reg\", LogisticRegression())])\n",
    "pipe_param_grid = [{\"log_reg__penalty\": [\"l1\", \"l2\"], \n",
    "                    \"log_reg__C\": [1e-2, 1e-1, 1, 1e1, 1e2]}]\n",
    "pipe_gs = GridSearchCV(pipe, pipe_param_grid, cv=5, scoring=\"f1\", verbose=1).fit(X_train, y_train)\n",
    "params = pipe_gs.best_params_\n",
    "print(pipe_gs.best_params_, pipe_gs.best_score_)\n",
    "print(confusion_matrix(y_test, pipe_gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
